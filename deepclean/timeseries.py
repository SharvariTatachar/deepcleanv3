import h5py
import copy#
from collections import OrderedDict

import numpy as np

import torch

from torch.utils.data import Dataset 
from gwpy.timeseries import TimeSeries, TimeSeriesDict
import deepclean as dc 
import deepclean.signal as sig
from deepclean.signal import bandpass


class TimeSeriesDataset:
    """ Torch dataset in timeseries format """

    def __init__(self):
        """ Initialized attributes """
        self.data = []
        self.channels = []
        self.t0 = 0.
        self.fs = 1.
        self.target_idx = None
        self.TimeseriesDict = None

        
    def download_data(self, channels, t0, duration, fs, nproc=4, resample_data = False): 
                
        """ Download data from the server"""
        # if channels is a file
        self.t0 = t0
        self.fs = fs
        if isinstance(channels, str):
            channels = open(channels).read().splitlines()

        channels, fake_chans = self.categorize_channels (channels)

        # get data and resample
        self.TimeseriesDict = TimeSeriesDict.get(channels, t0, 
                                            t0 + duration, nproc=nproc, allow_tape=True)
        if resample_data == True:
            self.TimeseriesDict = self.TimeseriesDict.resample(fs)

        
        
    def fetch(self, channels, t0, duration, fs, nproc=4):
        """ Fetch data """
        # if channels is a file
        if isinstance(channels, str):
            channels = open(channels).read().splitlines()
        target_channel = channels[0]

        channels, fake_chans = self.categorize_channels (channels)

        # get data and resample
        data = TimeSeriesDict.get(channels, t0, t0 + duration, nproc=nproc,
                                  allow_tape=True)

        data = self.add_fake_sinusoids (data, fake_chans, t0, duration, fs )

        data = data.resample(fs)

        # sorted by channel name
        data = OrderedDict(sorted(data.items()))

        # reset attributes 
        self.data = []
        self.channels = []
        for chan, ts in data.items():
            if np.mean(abs(ts.value)) > 0.0:             
                self.data.append(ts.value)
                self.channels.append(chan)
        self.data = np.stack(self.data)
        self.channels = np.stack(self.channels)
        self.t0 = t0
        self.fs = fs
        self.target_idx = np.where(self.channels == target_channel)[0][0]    


    def categorize_channels (self, channels):
        real_chans = []
        fake_chans = []
        for i in range(len(channels)):
            channel = channels[i]
            if 'FAKE_SINE_FREQ' in channel:
                fake_chans.append(channel)
            else:
                if channel != '':
                    real_chans.append(channel)

        return real_chans, fake_chans


    def add_fake_sinusoids (self, data, fake_chans, t0, duration, fs ):
        """ The dict 'data' is modified with fake timeseries """

        for chan in fake_chans:
            f0 = float(chan.split('_')[-1].split('HZ')[0].replace('POINT', '.'))
            time = np.linspace(t0, t0 + duration, int(duration*fs))
            sine_2pi_ft = np.sin(2*np.pi*f0*time)
            fake_ts = TimeSeries(sine_2pi_ft, t0=t0, sample_rate=fs, name=chan, unit="ct", channel=chan)
            data[chan] = fake_ts
        return data

    
    def read(self, fname, channels, start_time = None, end_time = None, group=None, t0=None, fs=None):
        """ Read data from HDF5 or NPZ format 
        
        Parameters
        ----------
        fname : str
            Path to the data file (.h5 or .npz format)
        channels : list or str
            List of channel names to load, or path to file containing channel names
        start_time : float, optional
            Start time for cropping data (default: None, uses t0 from file)
        end_time : float, optional
            End time for cropping data (default: None, uses full duration)
        group : str, optional
            Group name for HDF5 files (default: None)
        t0 : float, optional
            Start time if not in file metadata (default: None, will try to read from file)
        fs : float, optional
            Sample rate if not in file metadata. Defaults to 2048 Hz for .npz files if not specified
        """
        # if channels is a file
        if isinstance(channels, str):
            channels = open(channels).read().splitlines()
        target_channel = channels[0]
        
        # Detect file format
        file_ext = fname.split('.')[-1].lower()
        
        if file_ext == 'npz':
            # Read from NPZ format
            self.data = []
            self.channels = []
            
            with np.load(fname, allow_pickle=True) as f:
                # Get all keys in the file
                keys = list(f.keys())
                
                # Try to find metadata keys
                if 't0' in keys:
                    self.t0 = float(f['t0'])
                elif t0 is not None:
                    self.t0 = t0
                else:
                    self.t0 = 0.0
                
                if 'fs' in keys or 'sample_rate' in keys:
                    self.fs = float(f.get('fs', f.get('sample_rate', 2048.0)))
                elif fs is not None:
                    self.fs = fs
                else:
                    # Default to 2048 Hz as data is already resampled
                    self.fs = 2048.0
                
                # Load channel data
                for chan in channels:
                    if chan in keys:
                        self.channels.append(chan)
                        self.data.append(f[chan])
                    else:
                        # Try to find channel with case-insensitive matching or partial match
                        found = False
                        for key in keys:
                            if key.lower() == chan.lower() or chan in key or key in chan:
                                self.channels.append(chan)  # Use original channel name
                                self.data.append(f[key])
                                found = True
                                break
                        if not found:
                            print(f"Warning: Channel '{chan}' not found in file. Available keys: {keys}")
            
            if len(self.data) == 0:
                raise ValueError(f"No channels found in file. Available keys: {keys}")
                
        elif file_ext in ['h5', 'hdf5']:
            # Read from HDF5 format
            self.data = []
            self.channels = []
            metadata_set = False
            with h5py.File(fname, 'r') as f:
                if group is not None:
                    fobj = f[group]
                else:
                    fobj = f
                
                for chan, data in fobj.items():
                    if chan not in channels:
                        continue
                    self.channels.append(chan)
                    self.data.append(data[:])
                    # Get metadata from first channel (all should have same t0 and fs)
                    if not metadata_set:
                        self.t0 = data.attrs.get('t0', t0 if t0 is not None else 0.0)
                        self.fs = data.attrs.get('sample_rate', fs if fs is not None else 2048.0)
                        metadata_set = True
        else:
            raise ValueError(f"Unsupported file format: {file_ext}. Supported formats: .npz, .h5, .hdf5")
        
        self.data = np.stack(self.data)
        self.channels = np.array(self.channels)
        
        # sorted by channel name
        sorted_indices = np.argsort(self.channels)
        self.channels = self.channels[sorted_indices]
        self.data = self.data[sorted_indices]
        self.target_idx = np.where(self.channels == target_channel)[0][0]
        
        if start_time == None:
            start_time = self.t0
        if end_time == None:
            duration = self.data.shape[1]/self.fs
            end_time = self.t0 + duration
            
        idx_crop_start = int(self.fs * (start_time - self.t0))
        idx_crop_end   = int(self.fs * (end_time   - self.t0))
        self.data = self.data[:,idx_crop_start:idx_crop_end]
        self.t0   = start_time
        

                
    def write(self, fname, group=None, write_mode='w'):
        """ Write to HDF5 format. Can be read directly by gwpy.timeseries.TimeSeriesDict """
        with h5py.File(fname, write_mode) as f:
            # write to group if group is given
            if group is not None:
                fobj = f.create_group(group)
            else:
                fobj = f
            for chan, ts in zip(self.channels, self.data):
                dset = fobj.create_dataset(chan, data=ts, compression='gzip')
                dset.attrs['sample_rate'] = self.fs
                dset.attrs['t0'] = self.t0
                dset.attrs['channel'] = str(chan)
                dset.attrs['name'] = str(chan)
        
    def bandpass(self, fl, fh, order=8, channels=None):
        """ Bandpass filter data """
        if isinstance(fl, (list, tuple)):
            fl = fl[0]
        if isinstance(fh, (list, tuple)):
            fh = fh[-1]
            
        # create a copy of the class
        new = self.copy()
        
        # bandpassing
        if isinstance(channels, str):
            if channels == 'all':
                new.data = bandpass(new.data, self.fs, fl, fh, order)
            elif channels == 'target':
                new.data[new.target_idx] = bandpass(
                    new.data[new.target_idx], self.fs, fl, fh, order)
            elif channels == 'aux':
                for i, d in enumerate(new.data):
                    if i == new.target_idx:
                        continue
                    new.data[i] = bandpass(d, self.fs, fl, fh, order)
        elif isinstance(channels, list):
            for i, (chan, d) in enumerate(zip(new.channels, new.data)):
                if chan not in channels:
                    continue
                new.data[i] = bandpass(d, self.fs, fl, fh, order)
        
        return new

    def normalize(self, mean=None, std=None):
        """ Normalize data by mean and std """
        if mean is None:
            mean = self.mean
        if std is None:
            std = self.std

        new = self.copy()
        new.data = (new.data - mean) / std
        return new
                
    def copy(self):
        """ Return a copy of class """
        return copy.deepcopy(self)
        
    def get(self, channels):
        """ Return data from given channels """        
        data = []
        for chan, d in zip(self.channels, self.data):
            if chan not in channels:
                continue
            data.append(d)
        data = np.stack(data)
        return data
    
    def get_target(self):
        """ Get target channel """
        return self.data[self.target_idx]
        
    @property
    def mean(self):
        """ Return mean of each channel """
        return self.data.mean(axis=-1, keepdims=True)
        
    @property
    def std(self):
        """ Return std of each channel """
        return self.data.std(axis=-1, keepdims=True)

    @property
    def n_channels(self):
        """ Return number of channels 2"""
        return len(self.channels)


class TimeSeriesSegmentDataset(TimeSeriesDataset):
    """ Torch timeseries dataset with segment """
    
    def __init__(self, kernel, stride, pad_mode='median'):
        
        super().__init__()
        
        self.kernel = kernel
        self.stride = stride
        self.pad_mode = pad_mode
        
    def __len__(self):
        """ Return the number of stride """
        nsamp = self.data.shape[-1]
        kernel = int(self.kernel * self.fs)
        stride = int(self.stride * self.fs)
        n_stride = int(np.ceil((nsamp - kernel) / stride) + 1)
        return max(0, n_stride)
        
    def __getitem__(self, idx):
        """ Get sample Tensor for a given index """
        # check if idx is valid:
        if idx < 0:
            idx +=  self.__len__()
        if idx >= self.__len__():
            raise IndexError(
                f'index {idx} is out of bound with size {self.__len__()}.')
        
        # get sample
        kernel = int(self.kernel * self.fs)
        stride = int(self.stride * self.fs)
        idx_start = idx * stride
        idx_stop = idx_start + kernel
        data = self.data[:, idx_start: idx_stop].copy()
        
        # apply padding if needed
        nsamp = data.shape[-1]
        if nsamp < kernel:
            pad = kernel - nsamp
            data = np.pad(data, ((0, 0), (0, pad)), mode=self.pad_mode)
            
        # separate into target HOFT and aux channel
        target = data[self.target_idx]
        aux = np.delete(data, self.target_idx, axis=0)
            
        # convert into Tensor
        target = torch.Tensor(target)
        aux = torch.Tensor(aux)
        
        return aux, target

class SingleDataset(Dataset): 
    """
    Wrap a dataset to use one fixed index
    """
    def __init__(self, base_ds, fixed_idx: int =0): 
        self.base_ds = base_ds
        self.fixed_idx = fixed_idx
    
    def __len__(self): 
        return 1
    
    def __getitem__(self, idx):
        return self.base_ds[self.fixed_idx]